#!/bin/bash    # æŒ‡å®šè„šæœ¬ä½¿ç”¨ Bash è§£é‡Šå™¨

# ========== å®žéªŒæ—¥å¿—ä¸Žæ¨¡åž‹ä¿å­˜ç›®å½• ==========
LOG_DIR="log_vq_sft"    # æ—¥å¿—æ–‡ä»¶å¤¹åç§°
mkdir -p "$LOG_DIR"     # è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»ºæ—¥å¿—ç›®å½•

BASE_CHECKPOINT_DIR="checkpoints_vq_sft"   # æ¨¡åž‹ checkpoint æ ¹ç›®å½•
mkdir -p "$BASE_CHECKPOINT_DIR"            # è‹¥ä¸å­˜åœ¨åˆ™åˆ›å»º checkpoint ç›®å½•

# ========== ä½ å¯ä»¥è‡ªç”±ä¿®æ”¹çš„å˜é‡ ==========
LEARNING_RATES=(1e-5)   # å­¦ä¹ çŽ‡åˆ—è¡¨ï¼ˆå¯å¤šç»„å®žéªŒï¼‰
EPOCHS_LIST=(2)         # epoch åˆ—è¡¨ï¼ˆå¯å¤šç»„å®žéªŒï¼‰
VQ_TYPE="ResidualVQ"    # VQ ç±»åž‹ï¼ˆå¦‚ ResidualVQ æˆ–å…¶ä»– VQ æ¨¡åž‹ç±»åž‹ï¼‰
FROZEN=0                # æ˜¯å¦å†»ç»“é™¤è¾“å‡ºå±‚/embedding å¤–çš„æ‰€æœ‰å‚æ•°ï¼ˆ1=å†»ç»“ï¼Œ0=ä¸å†»ç»“ï¼‰

# å›ºå®šå‚æ•°
PRED_LEN=24             # é¢„æµ‹é•¿åº¦ï¼ˆæœªæ¥é¢„æµ‹å¤šå°‘æ­¥ï¼‰
SEQ_LEN=96              # è¾“å…¥åºåˆ—é•¿åº¦
Token_LEN=16            # Tokenizer ç”Ÿæˆçš„ token åºåˆ—é•¿åº¦
D_MODEL=64              # Transformer æ¨¡åž‹çš„ d_model ç»´åº¦
N_EMBED=256             # embedding/codebook ç»´åº¦

BATCH_SIZE=4            # batch å¤§å°
ELECT_RATE=1            # elect_rateï¼ˆç”¨äºŽ elect token çš„ç­–ç•¥ï¼‰
PRETRAIN_LR=1e-3        # é¢„è®­ç»ƒå­¦ä¹ çŽ‡
DEVICES="0,2"           # æŒ‡å®šä½¿ç”¨ GPU 0 å’Œ 2

# ========== æ˜¾å¼æŒ‡å®šä½ æƒ³ç”¨çš„ GPU ==========
export CUDA_VISIBLE_DEVICES=$DEVICES   # è®¾ç½®å¯è§ GPUï¼Œä»…ä½¿ç”¨é€‰å®šçš„ GPU

# ========== å¯åŠ¨å®žéªŒ ==========
for LR in "${LEARNING_RATES[@]}"; do      # éåŽ†å­¦ä¹ çŽ‡ç»„åˆ
    for EPOCHS in "${EPOCHS_LIST[@]}"; do # éåŽ† epoch ç»„åˆ

        VQVAE_PATH="./TSTokenizer/checkpoints/CzeLan_96_dm64_dr0.2_emb256_wl4_bl2_ResidualVQ_unfreeze_codebook"   # VQ-VAE tokenizer æ¨¡åž‹è·¯å¾„
                
        CHECKPOINT_DIR="${BASE_CHECKPOINT_DIR}/pred_${PRED_LEN}_seq_${SEQ_LEN}/lr_${LR}_ep_${EPOCHS}_vq_${VQ_TYPE}_chat_mask_64_pretrain_frozen_${FROZEN}"  # å½“å‰å®žéªŒçš„ checkpoint ä¿å­˜è·¯å¾„

        LOG_FILE="$LOG_DIR/experiment_pred_${PRED_LEN}_seq${SEQ_LEN}_lr_${LR}_ep_${EPOCHS}_$(date +'%Y%m%d_%H%M%S')_pretrain_frozen_${FROZEN}.log"   # æ¯æ¬¡å®žéªŒç”Ÿæˆç‹¬ç«‹çš„æ—¥å¿—æ–‡ä»¶

        echo "ðŸ”¹ Running experiment with lr=$LR, epochs=$EPOCHS, frozen=$FROZEN on GPUs $DEVICES"   # è¾“å‡ºå½“å‰å®žéªŒå‚æ•°

        accelerate launch \                       # ä½¿ç”¨ accelerate å¯åŠ¨å¤š GPU è®­ç»ƒ
            --multi_gpu \                         # å¯ç”¨å¤š GPU
            --num_processes 2 \                   # ä½¿ç”¨ä¸¤ä¸ªè¿›ç¨‹ï¼ˆä¸Ž GPU æ•°å¯¹åº”ï¼‰
            --main_process_port 29600 \           # ä¸»è¿›ç¨‹é€šä¿¡ç«¯å£
            run.py \                              # ä¸»è®­ç»ƒè„šæœ¬
            --is_training 1 \                     # å¯ç”¨è®­ç»ƒæ¨¡å¼
            --pretrain 1 \                        # å¼€å¯é¢„è®­ç»ƒé˜¶æ®µ
            --shuffle 0 \                         # æ•°æ®æ˜¯å¦ shuffleï¼ˆ0=å¦ï¼‰
            --batch_size "$BATCH_SIZE" \          # batch å¤§å°
            --data CzeLan \                       # æ•°æ®é›†åç§°
            --root_path "/data/tinyy/first/CrossTimeNet/dataset" \   # æ•°æ®é›†æ ¹è·¯å¾„
            --data_path "CzeLan.csv" \            # æ•°æ®æ–‡ä»¶åç§°
            --pred_len "$PRED_LEN" \              # é¢„æµ‹é•¿åº¦
            --seq_len "$SEQ_LEN" \                # è¾“å…¥åºåˆ—é•¿åº¦
            --token_len "$Token_LEN" \            # token åºåˆ—é•¿åº¦
            --n_embed "$N_EMBED" \                # embedding ç»´åº¦
            --d_model "$D_MODEL" \                # Transformer çš„éšè—ç»´åº¦
            --learning_rate "$LR" \               # å­¦ä¹ çŽ‡
            --weight_decay 0 \                    # æƒé‡è¡°å‡
            --model "qwen4ts" \                   # æ¨¡åž‹åç§°ï¼ˆè‡ªå®šä¹‰ qwen4tsï¼‰
            --task_name "long_term_forecast_bert_v4" \   # ä»»åŠ¡åç§°
            --vqvae_model_path "$VQVAE_PATH" \    # æŒ‡å®š VQ-VAE æ¨¡åž‹è·¯å¾„
            --dropout 0.1 \                       # dropout æ¯”ä¾‹
            --chan_indep 0 \                      # æ˜¯å¦é€šé“ç‹¬ç«‹ï¼ˆ0=å¦ï¼‰
            --enc_in 11 \                         # è¾“å…¥ç‰¹å¾ç»´åº¦
            --feat_dim 11 \                       # ç‰¹å¾ç»´åº¦
            --local_model_path "/data/tinyy/first/CrossTimeNet/2-models/Qwen2.5-0.5B" \  # LLM æœ¬åœ°è·¯å¾„
            --pretrained_model "checkpoints_pretrain/pred_720_seq_512/lr_1e-5_ep_10_vq_ResidualVQ_chat_mask_64_pretrain_frozen_0_0.5/long_term_forecast_bert_v4_ETTh1_qwen4ts_720_ResidualVQ/checkpoint.pth" \  # é¢„è®­ç»ƒæ¨¡åž‹è·¯å¾„
            --frozen "$FROZEN" \                  # æ˜¯å¦å†»ç»“éƒ¨åˆ†å‚æ•°
            --zero 1 \                            # zero-shot å‚æ•°ï¼Ÿè‡ªå®šä¹‰
            --layers 1 \                          # æ¨¡åž‹å±‚æ•°
            --params 1 \                          # è°ƒæ•´æ¨¡åž‹å‚æ•°è§„æ¨¡
            --wave_length 4 \                     # wave embedding ç›¸å…³å‚æ•°
            --checkpoints "$CHECKPOINT_DIR" \     # checkpoint ä¿å­˜è·¯å¾„
            --seed 42 \                           # éšæœºç§å­
            --init_method "word" \                # embedding åˆå§‹åŒ–æ–¹å¼
            --train_epochs "$EPOCHS" \            # è®­ç»ƒ epoch æ•°
            --pretrain_lr "$PRETRAIN_LR" \        # é¢„è®­ç»ƒå­¦ä¹ çŽ‡
            --use_multi_gpu \                     # å¯ç”¨å¤š GPU
            --elect_rate "$ELECT_RATE" \          # elect rate
            --VQ_type "$VQ_TYPE" \                # VQ ç±»åž‹
            --accumulation_steps 4 \              # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
            --test 0 \                            # æ˜¯å¦åªæµ‹è¯•ï¼ˆ0=è®­ç»ƒï¼‰
            > "$LOG_FILE" 2>&1                    # å°†è¾“å‡ºä¸Žé”™è¯¯å†™å…¥æ—¥å¿—æ–‡ä»¶
    done
done
